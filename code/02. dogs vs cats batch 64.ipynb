{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of train set : 20000\n",
      "the number of validn set : 4000\n",
      "the number of test set : 1000\n"
     ]
    }
   ],
   "source": [
    "# 경로 지정하기\n",
    "\n",
    "# 파일이 있는 경로\n",
    "train_dir = '../dogs-vs-cats/train/train'\n",
    "\n",
    "# train용 폴더 경로\n",
    "train_set_dir = os.path.join(train_dir, 'train_set')\n",
    "train_dog_dir = os.path.join(train_set_dir, 'dog')\n",
    "train_cat_dir = os.path.join(train_set_dir, 'cat')\n",
    "\n",
    "# valid용 폴더 경로\n",
    "valid_set_dir = os.path.join(train_dir, 'valid_set')\n",
    "valid_dog_dir = os.path.join(valid_set_dir, 'dog')\n",
    "valid_cat_dir = os.path.join(valid_set_dir, 'cat')\n",
    "\n",
    "# test용 폴더 경로\n",
    "test_set_dir = os.path.join(train_dir, 'test_set')\n",
    "test_dog_dir = os.path.join(test_set_dir, 'dog')\n",
    "test_cat_dir = os.path.join(test_set_dir, 'cat')\n",
    "\n",
    "# training set 20000장(cat:10000/dog:10000), cross-validation set 4000장(cat:2000/dog:2000), test set 1000장(cat:500/dog:500)\n",
    "print(f'the number of train set : {len(os.listdir(train_dog_dir)) + len(os.listdir(train_cat_dir))}')\n",
    "print(f'the number of validn set : {len(os.listdir(valid_dog_dir)) + len(os.listdir(valid_cat_dir))}')\n",
    "print(f'the number of test set : {len(os.listdir(test_dog_dir)) + len(os.listdir(test_cat_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator를 통해서 data generator를 생성\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, # nomalization 적용\n",
    "                                                                rotation_range=40,# 사진 회전 각도 범위 (0~180)\n",
    "                                                                width_shift_range=0.2, #수평 이동 범위(비율값)\n",
    "                                                                height_shift_range=0.2, #수직 이동 범위(비율값)\n",
    "                                                                shear_range=0.2,# 전단변환을 적용할 각도 범위; 사진을 3d로 기울임\n",
    "                                                                zoom_range=0.2, # 사진 확대 범위\n",
    "                                                                horizontal_flip=True, # 랜덤하게 이미지를 수평으로 뒤집음\n",
    "                                                                fill_mode='nearest') # 회전이나 이동을 통해 빈 곳이 생기면 픽셀을 채움(nearest는 인접합 픽셀 사용)\n",
    "\n",
    "# rescale 파라미터를 이용해 모든 데이터 255로 나누어주기\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# flow_from_directory() 메서드를 이용해서 훈령과 테스트에 사용될 이미지 데이터 만들기\n",
    "train_generator = train_datagen.flow_from_directory(train_set_dir, # 이미지들이 위치한 경로\n",
    "                                                    target_size=(150,150), # 이미지의 크기 조절\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_set_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_set_dir,\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=64,\n",
    "                                                  class_mode='binary')\n",
    "\n",
    "train_step = train_generator.n // 64\n",
    "valid_step = valid_generator.n // 64\n",
    "test_step = test_generator.n // 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step: 312\n",
      "valid_step: 62\n",
      "test_step: 15\n"
     ]
    }
   ],
   "source": [
    "print('train_step:', train_step)\n",
    "print('valid_step:',valid_step)\n",
    "print('test_step:', test_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              10617856  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 11,384,001\n",
      "Trainable params: 11,384,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cnn 모델 구현\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(150,150,3)),\n",
    "  tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(1024, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "312/312 [==============================] - 495s 2s/step - loss: 0.6751 - acc: 0.5620 - val_loss: 0.6563 - val_acc: 0.6190\n",
      "Epoch 2/30\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.6562 - acc: 0.6097 - val_loss: 0.6829 - val_acc: 0.6114\n",
      "Epoch 3/30\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.6027 - acc: 0.6738 - val_loss: 0.5028 - val_acc: 0.7513\n",
      "Epoch 4/30\n",
      "312/312 [==============================] - 467s 1s/step - loss: 0.5541 - acc: 0.7161 - val_loss: 0.5205 - val_acc: 0.7457\n",
      "Epoch 5/30\n",
      "312/312 [==============================] - 461s 1s/step - loss: 0.5358 - acc: 0.7284 - val_loss: 0.4500 - val_acc: 0.7961\n",
      "Epoch 6/30\n",
      "312/312 [==============================] - 464s 1s/step - loss: 0.5150 - acc: 0.7431 - val_loss: 0.4595 - val_acc: 0.7840\n",
      "Epoch 7/30\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.5014 - acc: 0.7552 - val_loss: 0.4243 - val_acc: 0.8110\n",
      "Epoch 8/30\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.4729 - acc: 0.7785 - val_loss: 0.3755 - val_acc: 0.8385\n",
      "Epoch 9/30\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.4457 - acc: 0.7901 - val_loss: 0.3736 - val_acc: 0.8256\n",
      "Epoch 10/30\n",
      "312/312 [==============================] - 460s 1s/step - loss: 0.4281 - acc: 0.8014 - val_loss: 0.3433 - val_acc: 0.8581\n",
      "Epoch 11/30\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.4109 - acc: 0.8123 - val_loss: 0.3279 - val_acc: 0.8576\n",
      "Epoch 12/30\n",
      "312/312 [==============================] - 460s 1s/step - loss: 0.3900 - acc: 0.8264 - val_loss: 0.3095 - val_acc: 0.8647\n",
      "Epoch 13/30\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.3682 - acc: 0.8384 - val_loss: 0.2984 - val_acc: 0.8753\n",
      "Epoch 14/30\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.3545 - acc: 0.8445 - val_loss: 0.3058 - val_acc: 0.8599\n",
      "Epoch 15/30\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.3447 - acc: 0.8477 - val_loss: 0.2855 - val_acc: 0.8765\n",
      "Epoch 16/30\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.3299 - acc: 0.8541 - val_loss: 0.2787 - val_acc: 0.8861\n",
      "Epoch 17/30\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.3223 - acc: 0.8595 - val_loss: 0.3016 - val_acc: 0.8672\n",
      "Epoch 18/30\n",
      "312/312 [==============================] - 462s 1s/step - loss: 0.3079 - acc: 0.8651 - val_loss: 0.2679 - val_acc: 0.8866\n",
      "Epoch 19/30\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.3005 - acc: 0.8711 - val_loss: 0.2422 - val_acc: 0.9032\n",
      "Epoch 20/30\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.2950 - acc: 0.8725 - val_loss: 0.2581 - val_acc: 0.8954\n",
      "Epoch 21/30\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.2896 - acc: 0.8764 - val_loss: 0.2698 - val_acc: 0.8906\n",
      "Epoch 22/30\n",
      "312/312 [==============================] - 469s 2s/step - loss: 0.2837 - acc: 0.8784 - val_loss: 0.2179 - val_acc: 0.9100\n",
      "Epoch 23/30\n",
      "312/312 [==============================] - 475s 2s/step - loss: 0.2744 - acc: 0.8829 - val_loss: 0.2122 - val_acc: 0.9171\n",
      "Epoch 24/30\n",
      "312/312 [==============================] - 460s 1s/step - loss: 0.2655 - acc: 0.8887 - val_loss: 0.2144 - val_acc: 0.9118\n",
      "Epoch 25/30\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.2639 - acc: 0.8892 - val_loss: 0.2248 - val_acc: 0.9047\n",
      "Epoch 26/30\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.2565 - acc: 0.8917 - val_loss: 0.2124 - val_acc: 0.9100\n",
      "Epoch 27/30\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.2520 - acc: 0.8937 - val_loss: 0.1944 - val_acc: 0.9229\n",
      "Epoch 28/30\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.2561 - acc: 0.8906 - val_loss: 0.1938 - val_acc: 0.9229\n",
      "Epoch 29/30\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.2498 - acc: 0.8966 - val_loss: 0.2119 - val_acc: 0.9103\n",
      "Epoch 30/30\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.2452 - acc: 0.8955 - val_loss: 0.2076 - val_acc: 0.9151\n",
      "==========================================================================================================================================\n",
      "time : 13832.005680561066\n",
      "==========================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : 0.2127 / test acc : 90.00 %\n"
     ]
    }
   ],
   "source": [
    "# 최적화\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), # 정규화? 최적화? 훈련과정 설정. 최적화 알고리즘 설정\n",
    "              loss='binary_crossentropy', # 모델 최적화에 사용되는 목적함수\n",
    "              metrics=['acc']) # 훈련을 모니터링 하기위해 사용\n",
    "\n",
    "# 모델 학습하기\n",
    "''' fit() 과 fit_generator() 차이?\n",
    "fit() : 사이킷런의 fit 메소드와 유사. 학습에 사용할 데이터 x와 y 전체를 한번에 입력으로 사용 -> 메모리 많이 사용\n",
    "fit_generator() : 파이썬의 generator를 사용한 것. 대용량을 데이터를 효율적으로 학습하기 위한 것\n",
    "파이썬의 generator를 통해 형성된 데이터들을 batch-by-batch로 학습하는 방법 -> cpu를 parallel(평행? 병렬?)하게 사용할 때 효율적\n",
    "'''\n",
    "\n",
    "start= time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_step, # steps_per_epoch : 한 번의 epoch에서 훈련에 사용할 batch의 개수 지정\n",
    "                    epochs=30, # epoch : 데이터셋을 한 번 훈련하는 과정\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_step # validation_steps : 한 번의 epoch이 끝날 때, 테스트에 사용되는 batch의 개수 지정\n",
    "                    )\n",
    "\n",
    "\n",
    "# model.fit(train_generator,\n",
    "#                     steps_per_epoch=train_step,\n",
    "#                     epochs=30,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=valid_step\n",
    "#                     )\n",
    "\n",
    "print('==========================================================================================================================================')\n",
    "print('time :', time.time()-start)\n",
    "print('==========================================================================================================================================')\n",
    "\n",
    "# 테스트용 데이터로 평가\n",
    "\n",
    "model.save('CNN_epoch_30_batch_64.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator,\n",
    "                                               steps=test_step,\n",
    "                                               workers=4)\n",
    "\n",
    "print(f'test loss : {test_loss:.4f} / test acc : {test_acc*100:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8422238001558515"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13832.005680561066/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "312/312 [==============================] - 624s 2s/step - loss: 0.2467 - acc: 0.8963 - val_loss: 0.2130 - val_acc: 0.9115\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - 486s 2s/step - loss: 0.2408 - acc: 0.8986 - val_loss: 0.1768 - val_acc: 0.9312\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - 477s 2s/step - loss: 0.2362 - acc: 0.8996 - val_loss: 0.2176 - val_acc: 0.9115\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - 461s 1s/step - loss: 0.2404 - acc: 0.8993 - val_loss: 0.2065 - val_acc: 0.9178\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.2322 - acc: 0.9018 - val_loss: 0.1989 - val_acc: 0.9115\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - 477s 2s/step - loss: 0.2277 - acc: 0.9043 - val_loss: 0.1873 - val_acc: 0.9259\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - 487s 2s/step - loss: 0.2241 - acc: 0.9060 - val_loss: 0.1941 - val_acc: 0.9236\n",
      "Epoch 8/50\n",
      "312/312 [==============================] - 483s 2s/step - loss: 0.2186 - acc: 0.9079 - val_loss: 0.2007 - val_acc: 0.9221\n",
      "Epoch 9/50\n",
      "312/312 [==============================] - 477s 2s/step - loss: 0.2239 - acc: 0.9075 - val_loss: 0.1762 - val_acc: 0.9254\n",
      "Epoch 10/50\n",
      "312/312 [==============================] - 479s 2s/step - loss: 0.2165 - acc: 0.9079 - val_loss: 0.1875 - val_acc: 0.9229\n",
      "Epoch 11/50\n",
      "312/312 [==============================] - 483s 2s/step - loss: 0.2131 - acc: 0.9112 - val_loss: 0.2272 - val_acc: 0.9085\n",
      "Epoch 12/50\n",
      "312/312 [==============================] - 485s 2s/step - loss: 0.2086 - acc: 0.9135 - val_loss: 0.1616 - val_acc: 0.9355\n",
      "Epoch 13/50\n",
      "312/312 [==============================] - 465s 1s/step - loss: 0.2119 - acc: 0.9111 - val_loss: 0.2302 - val_acc: 0.9027\n",
      "Epoch 14/50\n",
      "312/312 [==============================] - 455s 1s/step - loss: 0.2130 - acc: 0.9118 - val_loss: 0.1784 - val_acc: 0.9269\n",
      "Epoch 15/50\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.2091 - acc: 0.9127 - val_loss: 0.1817 - val_acc: 0.9292\n",
      "Epoch 16/50\n",
      "312/312 [==============================] - 455s 1s/step - loss: 0.2072 - acc: 0.9133 - val_loss: 0.1902 - val_acc: 0.9146\n",
      "Epoch 17/50\n",
      "312/312 [==============================] - 455s 1s/step - loss: 0.2067 - acc: 0.9131 - val_loss: 0.1653 - val_acc: 0.9307\n",
      "Epoch 18/50\n",
      "312/312 [==============================] - 454s 1s/step - loss: 0.2027 - acc: 0.9162 - val_loss: 0.1760 - val_acc: 0.9312\n",
      "Epoch 19/50\n",
      "312/312 [==============================] - 455s 1s/step - loss: 0.2013 - acc: 0.9160 - val_loss: 0.1792 - val_acc: 0.9287\n",
      "Epoch 20/50\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.1984 - acc: 0.9169 - val_loss: 0.1738 - val_acc: 0.9297\n",
      "Epoch 21/50\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.1972 - acc: 0.9172 - val_loss: 0.2018 - val_acc: 0.9196\n",
      "Epoch 22/50\n",
      "312/312 [==============================] - 455s 1s/step - loss: 0.1994 - acc: 0.9175 - val_loss: 0.2136 - val_acc: 0.9110\n",
      "Epoch 23/50\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.1944 - acc: 0.9181 - val_loss: 0.1696 - val_acc: 0.9345\n",
      "Epoch 24/50\n",
      "312/312 [==============================] - 454s 1s/step - loss: 0.1898 - acc: 0.9204 - val_loss: 0.1810 - val_acc: 0.9272\n",
      "Epoch 25/50\n",
      "312/312 [==============================] - 455s 1s/step - loss: 0.1879 - acc: 0.9217 - val_loss: 0.2045 - val_acc: 0.9183\n",
      "Epoch 26/50\n",
      "312/312 [==============================] - 455s 1s/step - loss: 0.1856 - acc: 0.9215 - val_loss: 0.1602 - val_acc: 0.9370\n",
      "Epoch 27/50\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.1950 - acc: 0.9202 - val_loss: 0.1670 - val_acc: 0.9355\n",
      "Epoch 28/50\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.1883 - acc: 0.9223 - val_loss: 0.1597 - val_acc: 0.9383\n",
      "Epoch 29/50\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.1890 - acc: 0.9239 - val_loss: 0.1502 - val_acc: 0.9433\n",
      "Epoch 30/50\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.1920 - acc: 0.9195 - val_loss: 0.1652 - val_acc: 0.9395\n",
      "Epoch 31/50\n",
      "312/312 [==============================] - 481s 2s/step - loss: 0.1892 - acc: 0.9224 - val_loss: 0.1667 - val_acc: 0.9352\n",
      "Epoch 32/50\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.1798 - acc: 0.9252 - val_loss: 0.1701 - val_acc: 0.9405\n",
      "Epoch 33/50\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.1849 - acc: 0.9253 - val_loss: 0.1574 - val_acc: 0.9388\n",
      "Epoch 34/50\n",
      "312/312 [==============================] - 455s 1s/step - loss: 0.1794 - acc: 0.9265 - val_loss: 0.1677 - val_acc: 0.9388\n",
      "Epoch 35/50\n",
      "312/312 [==============================] - 537s 2s/step - loss: 0.1885 - acc: 0.9202 - val_loss: 0.1547 - val_acc: 0.9420\n",
      "Epoch 36/50\n",
      "312/312 [==============================] - 522s 2s/step - loss: 0.1820 - acc: 0.9241 - val_loss: 0.1449 - val_acc: 0.9425\n",
      "Epoch 37/50\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.1808 - acc: 0.9261 - val_loss: 0.1569 - val_acc: 0.9340\n",
      "Epoch 38/50\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.1820 - acc: 0.9244 - val_loss: 0.1491 - val_acc: 0.9441\n",
      "Epoch 39/50\n",
      "312/312 [==============================] - 458s 1s/step - loss: 0.1814 - acc: 0.9264 - val_loss: 0.1660 - val_acc: 0.9393\n",
      "Epoch 40/50\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.1835 - acc: 0.9246 - val_loss: 0.1569 - val_acc: 0.9378\n",
      "Epoch 41/50\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.1791 - acc: 0.9260 - val_loss: 0.1609 - val_acc: 0.9420\n",
      "Epoch 42/50\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.1769 - acc: 0.9271 - val_loss: 0.1849 - val_acc: 0.9204\n",
      "Epoch 43/50\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.1712 - acc: 0.9302 - val_loss: 0.1346 - val_acc: 0.9476\n",
      "Epoch 44/50\n",
      "312/312 [==============================] - 457s 1s/step - loss: 0.1704 - acc: 0.9294 - val_loss: 0.1498 - val_acc: 0.9428\n",
      "Epoch 45/50\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.1722 - acc: 0.9274 - val_loss: 0.1774 - val_acc: 0.9352\n",
      "Epoch 46/50\n",
      "312/312 [==============================] - 456s 1s/step - loss: 0.1743 - acc: 0.9309 - val_loss: 0.1463 - val_acc: 0.9456\n",
      "Epoch 47/50\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.1738 - acc: 0.9265 - val_loss: 0.1630 - val_acc: 0.9372\n",
      "Epoch 48/50\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.1679 - acc: 0.9320 - val_loss: 0.1497 - val_acc: 0.9413\n",
      "Epoch 49/50\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.1749 - acc: 0.9291 - val_loss: 0.1623 - val_acc: 0.9395\n",
      "Epoch 50/50\n",
      "312/312 [==============================] - 459s 1s/step - loss: 0.1686 - acc: 0.9310 - val_loss: 0.1910 - val_acc: 0.9244\n",
      "==========================================================================================================================================\n",
      "time : 23407.764326810837\n",
      "==========================================================================================================================================\n",
      "test loss : 0.1768 / test acc : 92.81 %\n"
     ]
    }
   ],
   "source": [
    "# 최적화\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), # 정규화? 최적화? 훈련과정 설정. 최적화 알고리즘 설정\n",
    "              loss='binary_crossentropy', # 모델 최적화에 사용되는 목적함수\n",
    "              metrics=['acc']) # 훈련을 모니터링 하기위해 사용\n",
    "\n",
    "# 모델 학습하기\n",
    "''' fit() 과 fit_generator() 차이?\n",
    "fit() : 사이킷런의 fit 메소드와 유사. 학습에 사용할 데이터 x와 y 전체를 한번에 입력으로 사용 -> 메모리 많이 사용\n",
    "fit_generator() : 파이썬의 generator를 사용한 것. 대용량을 데이터를 효율적으로 학습하기 위한 것\n",
    "파이썬의 generator를 통해 형성된 데이터들을 batch-by-batch로 학습하는 방법 -> cpu를 parallel(평행? 병렬?)하게 사용할 때 효율적\n",
    "'''\n",
    "\n",
    "start= time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_step, # steps_per_epoch : 한 번의 epoch에서 훈련에 사용할 batch의 개수 지정\n",
    "                    epochs=50, # epoch : 데이터셋을 한 번 훈련하는 과정\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_step # validation_steps : 한 번의 epoch이 끝날 때, 테스트에 사용되는 batch의 개수 지정\n",
    "                    )\n",
    "\n",
    "\n",
    "# model.fit(train_generator,\n",
    "#                     steps_per_epoch=train_step,\n",
    "#                     epochs=30,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=valid_step\n",
    "#                     )\n",
    "\n",
    "print('==========================================================================================================================================')\n",
    "print('time :', time.time()-start)\n",
    "print('==========================================================================================================================================')\n",
    "\n",
    "# 테스트용 데이터로 평가\n",
    "\n",
    "model.save('CNN_epoch_30_batch_64.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator,\n",
    "                                               steps=test_step,\n",
    "                                               workers=4)\n",
    "\n",
    "print(f'test loss : {test_loss:.4f} / test acc : {test_acc*100:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
