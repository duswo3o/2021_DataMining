{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of train set : 20000\n",
      "the number of validn set : 4000\n",
      "the number of test set : 1000\n"
     ]
    }
   ],
   "source": [
    "# 경로 지정하기\n",
    "\n",
    "# 파일이 있는 경로\n",
    "train_dir = '../dogs-vs-cats/train/train'\n",
    "\n",
    "# train용 폴더 경로\n",
    "train_set_dir = os.path.join(train_dir, 'train_set')\n",
    "train_dog_dir = os.path.join(train_set_dir, 'dog')\n",
    "train_cat_dir = os.path.join(train_set_dir, 'cat')\n",
    "\n",
    "# valid용 폴더 경로\n",
    "valid_set_dir = os.path.join(train_dir, 'valid_set')\n",
    "valid_dog_dir = os.path.join(valid_set_dir, 'dog')\n",
    "valid_cat_dir = os.path.join(valid_set_dir, 'cat')\n",
    "\n",
    "# test용 폴더 경로\n",
    "test_set_dir = os.path.join(train_dir, 'test_set')\n",
    "test_dog_dir = os.path.join(test_set_dir, 'dog')\n",
    "test_cat_dir = os.path.join(test_set_dir, 'cat')\n",
    "\n",
    "# training set 20000장(cat:10000/dog:10000), cross-validation set 4000장(cat:2000/dog:2000), test set 1000장(cat:500/dog:500)\n",
    "print(f'the number of train set : {len(os.listdir(train_dog_dir)) + len(os.listdir(train_cat_dir))}')\n",
    "print(f'the number of validn set : {len(os.listdir(valid_dog_dir)) + len(os.listdir(valid_cat_dir))}')\n",
    "print(f'the number of test set : {len(os.listdir(test_dog_dir)) + len(os.listdir(test_cat_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator를 통해서 data generator를 생성\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, # nomalization 적용\n",
    "                                                                rotation_range=40,# 사진 회전 각도 범위 (0~180)\n",
    "                                                                width_shift_range=0.2, #수평 이동 범위(비율값)\n",
    "                                                                height_shift_range=0.2, #수직 이동 범위(비율값)\n",
    "                                                                shear_range=0.2,# 전단변환을 적용할 각도 범위; 사진을 3d로 기울임\n",
    "                                                                zoom_range=0.2, # 사진 확대 범위\n",
    "                                                                horizontal_flip=True, # 랜덤하게 이미지를 수평으로 뒤집음\n",
    "                                                                fill_mode='nearest') # 회전이나 이동을 통해 빈 곳이 생기면 픽셀을 채움(nearest는 인접합 픽셀 사용)\n",
    "\n",
    "# rescale 파라미터를 이용해 모든 데이터 255로 나누어주기\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# flow_from_directory() 메서드를 이용해서 훈령과 테스트에 사용될 이미지 데이터 만들기\n",
    "train_generator = train_datagen.flow_from_directory(train_set_dir, # 이미지들이 위치한 경로\n",
    "                                                    target_size=(150,150), # 이미지의 크기 조절\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_set_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_set_dir,\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='binary')\n",
    "\n",
    "train_step = train_generator.n // 32\n",
    "valid_step = valid_generator.n // 32\n",
    "test_step = test_generator.n // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step: 625\n",
      "valid_step: 125\n",
      "test_step: 31\n"
     ]
    }
   ],
   "source": [
    "print('train_step:', train_step)\n",
    "print('valid_step:',valid_step)\n",
    "print('test_step:', test_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              10617856  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 11,384,001\n",
      "Trainable params: 11,384,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cnn 모델 구현\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(150,150,3)),\n",
    "  tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(1024, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 [==============================] - 535s 854ms/step - loss: 0.6279 - acc: 0.6423 - val_loss: 0.5404 - val_acc: 0.7375\n",
      "Epoch 2/30\n",
      "625/625 [==============================] - 441s 705ms/step - loss: 0.5835 - acc: 0.6899 - val_loss: 0.5267 - val_acc: 0.7520\n",
      "Epoch 3/30\n",
      "625/625 [==============================] - 444s 710ms/step - loss: 0.5555 - acc: 0.7175 - val_loss: 0.4686 - val_acc: 0.7690\n",
      "Epoch 4/30\n",
      "625/625 [==============================] - 443s 708ms/step - loss: 0.5299 - acc: 0.7366 - val_loss: 0.4895 - val_acc: 0.7715\n",
      "Epoch 5/30\n",
      "625/625 [==============================] - 451s 722ms/step - loss: 0.5117 - acc: 0.7516 - val_loss: 0.4191 - val_acc: 0.8065\n",
      "Epoch 6/30\n",
      "625/625 [==============================] - 449s 718ms/step - loss: 0.4864 - acc: 0.7691 - val_loss: 0.4039 - val_acc: 0.8207\n",
      "Epoch 7/30\n",
      "625/625 [==============================] - 450s 720ms/step - loss: 0.4552 - acc: 0.7850 - val_loss: 0.3676 - val_acc: 0.8400\n",
      "Epoch 8/30\n",
      "625/625 [==============================] - 447s 714ms/step - loss: 0.4415 - acc: 0.7951 - val_loss: 0.3606 - val_acc: 0.8443\n",
      "Epoch 9/30\n",
      "625/625 [==============================] - 450s 721ms/step - loss: 0.4148 - acc: 0.8132 - val_loss: 0.3784 - val_acc: 0.8528\n",
      "Epoch 10/30\n",
      "625/625 [==============================] - 446s 714ms/step - loss: 0.4033 - acc: 0.8193 - val_loss: 0.3291 - val_acc: 0.8612\n",
      "Epoch 11/30\n",
      "625/625 [==============================] - 449s 718ms/step - loss: 0.3814 - acc: 0.8295 - val_loss: 0.2928 - val_acc: 0.8758\n",
      "Epoch 12/30\n",
      "625/625 [==============================] - 447s 716ms/step - loss: 0.3764 - acc: 0.8306 - val_loss: 0.3679 - val_acc: 0.8393\n",
      "Epoch 13/30\n",
      "625/625 [==============================] - 452s 724ms/step - loss: 0.3636 - acc: 0.8431 - val_loss: 0.2842 - val_acc: 0.8800\n",
      "Epoch 14/30\n",
      "625/625 [==============================] - 450s 719ms/step - loss: 0.3469 - acc: 0.8466 - val_loss: 0.2913 - val_acc: 0.8815\n",
      "Epoch 15/30\n",
      "625/625 [==============================] - 449s 718ms/step - loss: 0.3344 - acc: 0.8530 - val_loss: 0.2545 - val_acc: 0.8957\n",
      "Epoch 16/30\n",
      "625/625 [==============================] - 452s 723ms/step - loss: 0.3222 - acc: 0.8579 - val_loss: 0.2586 - val_acc: 0.8953\n",
      "Epoch 17/30\n",
      "625/625 [==============================] - 453s 725ms/step - loss: 0.3182 - acc: 0.8588 - val_loss: 0.2433 - val_acc: 0.9022\n",
      "Epoch 18/30\n",
      "625/625 [==============================] - 453s 724ms/step - loss: 0.3144 - acc: 0.8623 - val_loss: 0.2543 - val_acc: 0.8910\n",
      "Epoch 19/30\n",
      "625/625 [==============================] - 455s 728ms/step - loss: 0.3141 - acc: 0.8642 - val_loss: 0.2696 - val_acc: 0.8882\n",
      "Epoch 20/30\n",
      "625/625 [==============================] - 454s 726ms/step - loss: 0.3045 - acc: 0.8666 - val_loss: 0.2356 - val_acc: 0.9015\n",
      "Epoch 21/30\n",
      "625/625 [==============================] - 458s 732ms/step - loss: 0.2946 - acc: 0.8739 - val_loss: 0.2378 - val_acc: 0.9003\n",
      "Epoch 22/30\n",
      "625/625 [==============================] - 457s 731ms/step - loss: 0.2950 - acc: 0.8733 - val_loss: 0.2482 - val_acc: 0.8975\n",
      "Epoch 23/30\n",
      "625/625 [==============================] - 458s 732ms/step - loss: 0.2869 - acc: 0.8814 - val_loss: 0.2434 - val_acc: 0.8995\n",
      "Epoch 24/30\n",
      "625/625 [==============================] - 457s 730ms/step - loss: 0.2871 - acc: 0.8778 - val_loss: 0.2096 - val_acc: 0.9175\n",
      "Epoch 25/30\n",
      "625/625 [==============================] - 460s 735ms/step - loss: 0.2809 - acc: 0.8800 - val_loss: 0.2210 - val_acc: 0.9125\n",
      "Epoch 26/30\n",
      "625/625 [==============================] - 458s 733ms/step - loss: 0.2752 - acc: 0.8817 - val_loss: 0.2081 - val_acc: 0.9128\n",
      "Epoch 27/30\n",
      "625/625 [==============================] - 462s 740ms/step - loss: 0.2760 - acc: 0.8812 - val_loss: 0.2592 - val_acc: 0.9015\n",
      "Epoch 28/30\n",
      "625/625 [==============================] - 460s 736ms/step - loss: 0.2730 - acc: 0.8827 - val_loss: 0.2056 - val_acc: 0.9155\n",
      "Epoch 29/30\n",
      "625/625 [==============================] - 463s 741ms/step - loss: 0.2642 - acc: 0.8881 - val_loss: 0.2130 - val_acc: 0.9155\n",
      "Epoch 30/30\n",
      "625/625 [==============================] - 462s 740ms/step - loss: 0.2690 - acc: 0.8851 - val_loss: 0.2803 - val_acc: 0.8953\n",
      "=====================================================================\n",
      "time : 13664.488302707672\n"
     ]
    }
   ],
   "source": [
    "# 최적화\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), # 정규화? 최적화? 훈련과정 설정. 최적화 알고리즘 설정\n",
    "              loss='binary_crossentropy', # 모델 최적화에 사용되는 목적함수\n",
    "              metrics=['acc']) # 훈련을 모니터링 하기위해 사용\n",
    "\n",
    "# 모델 학습하기\n",
    "''' fit() 과 fit_generator() 차이?\n",
    "fit() : 사이킷런의 fit 메소드와 유사. 학습에 사용할 데이터 x와 y 전체를 한번에 입력으로 사용 -> 메모리 많이 사용\n",
    "fit_generator() : 파이썬의 generator를 사용한 것. 대용량을 데이터를 효율적으로 학습하기 위한 것\n",
    "파이썬의 generator를 통해 형성된 데이터들을 batch-by-batch로 학습하는 방법 -> cpu를 parallel(평행? 병렬?)하게 사용할 때 효율적\n",
    "'''\n",
    "\n",
    "start= time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_step, # steps_per_epoch : 한 번의 epoch에서 훈련에 사용할 batch의 개수 지정\n",
    "                    epochs=30, # epoch : 데이터셋을 한 번 훈련하는 과정\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_step # validation_steps : 한 번의 epoch이 끝날 때, 테스트에 사용되는 batch의 개수 지정\n",
    "                    )\n",
    "print('=====================================================================')\n",
    "print('time :', time.time()-start)\n",
    "\n",
    "# model.fit(train_generator,\n",
    "#                     steps_per_epoch=train_step,\n",
    "#                     epochs=30,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=valid_step\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : 0.2772 / test acc : 89.72 %\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터로 평가\n",
    "\n",
    "model.save('CNN_epoch_30_batch_32.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator,\n",
    "                                               steps=test_step,\n",
    "                                               workers=4)\n",
    "\n",
    "print(f'test loss : {test_loss:.4f} / test acc : {test_acc*100:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 462s 739ms/step - loss: 0.2656 - acc: 0.8868 - val_loss: 0.2187 - val_acc: 0.9140\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 462s 740ms/step - loss: 0.2674 - acc: 0.8877 - val_loss: 0.2210 - val_acc: 0.9093\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 462s 739ms/step - loss: 0.2624 - acc: 0.8895 - val_loss: 0.2877 - val_acc: 0.8842\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 465s 743ms/step - loss: 0.2501 - acc: 0.8930 - val_loss: 0.2202 - val_acc: 0.9112\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 466s 746ms/step - loss: 0.2525 - acc: 0.8939 - val_loss: 0.2006 - val_acc: 0.9225\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 466s 746ms/step - loss: 0.2502 - acc: 0.8953 - val_loss: 0.1884 - val_acc: 0.9243\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 466s 746ms/step - loss: 0.2497 - acc: 0.8952 - val_loss: 0.2283 - val_acc: 0.9093\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 478s 765ms/step - loss: 0.2484 - acc: 0.8955 - val_loss: 0.2083 - val_acc: 0.9145\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 508s 813ms/step - loss: 0.2434 - acc: 0.8990 - val_loss: 0.1776 - val_acc: 0.9285\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 469s 750ms/step - loss: 0.2442 - acc: 0.8982 - val_loss: 0.1953 - val_acc: 0.9197\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 470s 751ms/step - loss: 0.2419 - acc: 0.8974 - val_loss: 0.1834 - val_acc: 0.9293\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 470s 751ms/step - loss: 0.2369 - acc: 0.9008 - val_loss: 0.2157 - val_acc: 0.9143\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 470s 751ms/step - loss: 0.2346 - acc: 0.9020 - val_loss: 0.2060 - val_acc: 0.9128\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 470s 751ms/step - loss: 0.2303 - acc: 0.9036 - val_loss: 0.1994 - val_acc: 0.9212\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 473s 756ms/step - loss: 0.2349 - acc: 0.9006 - val_loss: 0.1808 - val_acc: 0.9270\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 469s 750ms/step - loss: 0.2320 - acc: 0.9031 - val_loss: 0.2197 - val_acc: 0.9105\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 470s 752ms/step - loss: 0.2328 - acc: 0.9021 - val_loss: 0.1878 - val_acc: 0.9225\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2317 - acc: 0.9018 - val_loss: 0.1735 - val_acc: 0.9325\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2316 - acc: 0.9046 - val_loss: 0.2101 - val_acc: 0.9185\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 470s 751ms/step - loss: 0.2300 - acc: 0.9035 - val_loss: 0.2711 - val_acc: 0.8827\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2214 - acc: 0.9073 - val_loss: 0.1647 - val_acc: 0.9392\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 469s 750ms/step - loss: 0.2250 - acc: 0.9061 - val_loss: 0.2038 - val_acc: 0.9183\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2199 - acc: 0.9077 - val_loss: 0.1755 - val_acc: 0.9280\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2262 - acc: 0.9046 - val_loss: 0.1899 - val_acc: 0.9273\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 470s 752ms/step - loss: 0.2243 - acc: 0.9036 - val_loss: 0.1773 - val_acc: 0.9302\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2212 - acc: 0.9072 - val_loss: 0.1809 - val_acc: 0.9323\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 469s 751ms/step - loss: 0.2213 - acc: 0.9084 - val_loss: 0.2248 - val_acc: 0.9075\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 470s 752ms/step - loss: 0.2212 - acc: 0.9094 - val_loss: 0.2040 - val_acc: 0.9218\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 470s 751ms/step - loss: 0.2250 - acc: 0.9050 - val_loss: 0.2081 - val_acc: 0.9107\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2169 - acc: 0.9096 - val_loss: 0.1967 - val_acc: 0.9158\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 470s 753ms/step - loss: 0.2159 - acc: 0.9099 - val_loss: 0.2051 - val_acc: 0.9200\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2172 - acc: 0.9129 - val_loss: 0.1915 - val_acc: 0.9258\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2147 - acc: 0.9097 - val_loss: 0.1946 - val_acc: 0.9227\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2122 - acc: 0.9094 - val_loss: 0.2394 - val_acc: 0.9000\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2124 - acc: 0.9145 - val_loss: 0.1710 - val_acc: 0.9298\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 470s 752ms/step - loss: 0.2105 - acc: 0.9146 - val_loss: 0.1708 - val_acc: 0.9287\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2088 - acc: 0.9129 - val_loss: 0.1927 - val_acc: 0.9255\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2068 - acc: 0.9147 - val_loss: 0.1786 - val_acc: 0.9293\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 473s 756ms/step - loss: 0.2148 - acc: 0.9107 - val_loss: 0.1865 - val_acc: 0.9227\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 469s 750ms/step - loss: 0.2053 - acc: 0.9154 - val_loss: 0.1696 - val_acc: 0.9348\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 470s 753ms/step - loss: 0.2120 - acc: 0.9121 - val_loss: 0.2083 - val_acc: 0.9115\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 469s 750ms/step - loss: 0.1940 - acc: 0.9211 - val_loss: 0.1774 - val_acc: 0.9290\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 470s 752ms/step - loss: 0.2105 - acc: 0.9154 - val_loss: 0.1719 - val_acc: 0.9283\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 469s 751ms/step - loss: 0.2042 - acc: 0.9140 - val_loss: 0.2110 - val_acc: 0.9210\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2007 - acc: 0.9168 - val_loss: 0.1794 - val_acc: 0.9280\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2055 - acc: 0.9169 - val_loss: 0.1532 - val_acc: 0.9398\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.1989 - acc: 0.9173 - val_loss: 0.1761 - val_acc: 0.9352\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 470s 752ms/step - loss: 0.1979 - acc: 0.9181 - val_loss: 0.1656 - val_acc: 0.9367\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2050 - acc: 0.9141 - val_loss: 0.2167 - val_acc: 0.9020\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.1936 - acc: 0.9198 - val_loss: 0.1677 - val_acc: 0.9420\n",
      "=====================================================================\n",
      "time : 23529.407753944397\n"
     ]
    }
   ],
   "source": [
    "start= time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_step, # steps_per_epoch : 한 번의 epoch에서 훈련에 사용할 batch의 개수 지정\n",
    "                    epochs=50, # epoch : 데이터셋을 한 번 훈련하는 과정\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_step # validation_steps : 한 번의 epoch이 끝날 때, 테스트에 사용되는 batch의 개수 지정\n",
    "                    )\n",
    "print('=====================================================================')\n",
    "print('time :', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : 0.1717 / test acc : 93.25 %\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터로 평가\n",
    "\n",
    "model.save('CNN_epoch_50_batch_32.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator,\n",
    "                                               steps=test_step,\n",
    "                                               workers=4)\n",
    "\n",
    "print(f'test loss : {test_loss:.4f} / test acc : {test_acc*100:.2f} %')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
