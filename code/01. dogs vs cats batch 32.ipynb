{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일이 있는 경로\n",
    "train_dir = '../dogs-vs-cats/train/train'\n",
    "\n",
    "# train용 폴더 생성\n",
    "train_set_dir = os.path.join(train_dir, 'train_set')\n",
    "os.mkdir(train_set_dir) #폴더 생성\n",
    "train_dog_dir = os.path.join(train_set_dir, 'dog')\n",
    "os.mkdir(train_dog_dir)\n",
    "train_cat_dir = os.path.join(train_set_dir, 'cat')\n",
    "os.mkdir(train_cat_dir)\n",
    "\n",
    "# valid용 폴더 생성\n",
    "valid_set_dir = os.path.join(train_dir, 'valid_set')\n",
    "os.mkdir(valid_set_dir)\n",
    "valid_dog_dir = os.path.join(valid_set_dir, 'dog')\n",
    "os.mkdir(valid_dog_dir)\n",
    "valid_cat_dir = os.path.join(valid_set_dir, 'cat')\n",
    "os.mkdir(valid_cat_dir)\n",
    "\n",
    "# test용 폴더 생성\n",
    "test_set_dir = os.path.join(train_dir, 'test_set')\n",
    "os.mkdir(test_set_dir)\n",
    "test_dog_dir = os.path.join(test_set_dir, 'dog')\n",
    "os.mkdir(test_dog_dir)\n",
    "test_cat_dir = os.path.join(test_set_dir, 'cat')\n",
    "os.mkdir(test_cat_dir)\n",
    "\n",
    "# image file name list 생성\n",
    "dog_files = [f'dog.{i}.jpg' for i in range(12500)]\n",
    "cat_files = [f'cat.{i}.jpg' for i in range(12500)]\n",
    "\n",
    "# 각 폴더로 image 이동\n",
    "for file in dog_files[:10000]:\n",
    "  src = os.path.join(train_dir, file)\n",
    "  dst = os.path.join(train_dog_dir, file)\n",
    "  shutil.move(src, dst)\n",
    "\n",
    "for file in dog_files[10000:12000]:\n",
    "  src = os.path.join(train_dir, file)\n",
    "  dst = os.path.join(valid_dog_dir, file)\n",
    "  shutil.move(src, dst)\n",
    "\n",
    "for file in dog_files[12000:12500]:\n",
    "  src = os.path.join(train_dir, file)\n",
    "  dst = os.path.join(test_dog_dir, file)\n",
    "  shutil.move(src, dst)\n",
    "\n",
    "for file in cat_files[:10000]:\n",
    "  src = os.path.join(train_dir, file)\n",
    "  dst = os.path.join(train_cat_dir, file)\n",
    "  shutil.move(src, dst)\n",
    "\n",
    "for file in cat_files[10000:12000]:\n",
    "  src = os.path.join(train_dir,file)\n",
    "  dst = os.path.join(valid_cat_dir, file)\n",
    "  shutil.move(src, dst)\n",
    "\n",
    "for file in cat_files[12000:12500]:\n",
    "  src = os.path.join(train_dir, file)\n",
    "  dst = os.path.join(test_cat_dir, file)\n",
    "  shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of train set : 20000\n",
      "the number of validn set : 4000\n",
      "the number of test set : 1000\n"
     ]
    }
   ],
   "source": [
    "# training set 20000장(cat:10000/dog:10000), cross-validation set 4000장(cat:2000/dog:2000), test set 1000장(cat:500/dog:500)\n",
    "print(f'the number of train set : {len(os.listdir(train_dog_dir)) + len(os.listdir(train_cat_dir))}')\n",
    "print(f'the number of validn set : {len(os.listdir(valid_dog_dir)) + len(os.listdir(valid_cat_dir))}')\n",
    "print(f'the number of test set : {len(os.listdir(test_dog_dir)) + len(os.listdir(test_cat_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator를 통해서 data generator를 생성\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, # nomalization 적용\n",
    "                                                                rotation_range=40,# 사진 회전 각도 범위 (0~180)\n",
    "                                                                width_shift_range=0.2, #수평 이동 범위(비율값)\n",
    "                                                                height_shift_range=0.2, #수직 이동 범위(비율값)\n",
    "                                                                shear_range=0.2,# 전단변환을 적용할 각도 범위; 사진을 3d로 기울임\n",
    "                                                                zoom_range=0.2, # 사진 확대 범위\n",
    "                                                                horizontal_flip=True, # 랜덤하게 이미지를 수평으로 뒤집음\n",
    "                                                                fill_mode='nearest') # 회전이나 이동을 통해 빈 곳이 생기면 픽셀을 채움(nearest는 인접합 픽셀 사용)\n",
    "\n",
    "# rescale 파라미터를 이용해 모든 데이터 255로 나누어주기\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# flow_from_directory() 메서드를 이용해서 훈령과 테스트에 사용될 이미지 데이터 만들기\n",
    "train_generator = train_datagen.flow_from_directory(train_set_dir, # 이미지들이 위치한 경로\n",
    "                                                    target_size=(150,150), # 이미지의 크기 조절\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_set_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_set_dir,\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size=32,\n",
    "                                                  class_mode='binary')\n",
    "\n",
    "train_step = train_generator.n // 32\n",
    "valid_step = valid_generator.n // 32\n",
    "test_step = test_generator.n // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step: 625\n",
      "valid_step: 125\n",
      "test_step: 31\n"
     ]
    }
   ],
   "source": [
    "print('train_step:', train_step)\n",
    "print('valid_step:',valid_step)\n",
    "print('test_step:', test_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              10617856  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 11,384,001\n",
      "Trainable params: 11,384,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cnn 모델 구현\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(150,150,3)),\n",
    "  tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=1, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(1024, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최적화\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), # 정규화? 최적화? 훈련과정 설정. 최적화 알고리즘 설정\n",
    "              loss='binary_crossentropy', # 모델 최적화에 사용되는 목적함수\n",
    "              metrics=['acc']) # 훈련을 모니터링 하기위해 사용\n",
    "\n",
    "# 모델 학습하기\n",
    "''' fit() 과 fit_generator() 차이?\n",
    "fit() : 사이킷런의 fit 메소드와 유사. 학습에 사용할 데이터 x와 y 전체를 한번에 입력으로 사용 -> 메모리 많이 사용\n",
    "fit_generator() : 파이썬의 generator를 사용한 것. 대용량을 데이터를 효율적으로 학습하기 위한 것\n",
    "파이썬의 generator를 통해 형성된 데이터들을 batch-by-batch로 학습하는 방법 -> cpu를 parallel(평행? 병렬?)하게 사용할 때 효율적\n",
    "'''\n",
    "\n",
    "start= time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_step, # steps_per_epoch : 한 번의 epoch에서 훈련에 사용할 batch의 개수 지정\n",
    "                    epochs=30, # epoch : 데이터셋을 한 번 훈련하는 과정\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_step # validation_steps : 한 번의 epoch이 끝날 때, 테스트에 사용되는 batch의 개수 지정\n",
    "                    )\n",
    "print('=====================================================================')\n",
    "print('time :', time.time()-start)\n",
    "\n",
    "# model.fit(train_generator,\n",
    "#                     steps_per_epoch=train_step,\n",
    "#                     epochs=30,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=valid_step\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.921241510907809"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14116.469439268112/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 데이터로 평가\n",
    "\n",
    "model.save('CNN_epoch_30.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator,\n",
    "                                               steps=test_step,\n",
    "                                               workers=4)\n",
    "\n",
    "print(f'test loss : {test_loss:.4f} / test acc : {test_acc*100:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_step, # steps_per_epoch : 한 번의 epoch에서 훈련에 사용할 batch의 개수 지정\n",
    "                    epochs=50, # epoch : 데이터셋을 한 번 훈련하는 과정\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_step # validation_steps : 한 번의 epoch이 끝날 때, 테스트에 사용되는 batch의 개수 지정\n",
    "                    )\n",
    "print('=====================================================================')\n",
    "print('time :', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "23804.832839012146/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 데이터로 평가\n",
    "\n",
    "model.save('CNN_epoch_50.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator,\n",
    "                                               steps=test_step,\n",
    "                                               workers=4)\n",
    "\n",
    "print(f'test loss : {test_loss:.4f} / test acc : {test_acc*100:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - 600s 959ms/step - loss: 0.6905 - acc: 0.5300 - val_loss: 0.6785 - val_acc: 0.5742\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 455s 729ms/step - loss: 0.6812 - acc: 0.5633 - val_loss: 0.6656 - val_acc: 0.6018\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 448s 716ms/step - loss: 0.6488 - acc: 0.6263 - val_loss: 0.6224 - val_acc: 0.6325\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 447s 715ms/step - loss: 0.6242 - acc: 0.6543 - val_loss: 0.5784 - val_acc: 0.7032\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 446s 713ms/step - loss: 0.5988 - acc: 0.6805 - val_loss: 0.5171 - val_acc: 0.7538\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 447s 715ms/step - loss: 0.5715 - acc: 0.7067 - val_loss: 0.4785 - val_acc: 0.7807\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 449s 718ms/step - loss: 0.5411 - acc: 0.7294 - val_loss: 0.4603 - val_acc: 0.7732\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 457s 731ms/step - loss: 0.5134 - acc: 0.7531 - val_loss: 0.4669 - val_acc: 0.7807\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 450s 720ms/step - loss: 0.4911 - acc: 0.7632 - val_loss: 0.4181 - val_acc: 0.8105\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 451s 721ms/step - loss: 0.4734 - acc: 0.7777 - val_loss: 0.4031 - val_acc: 0.8165\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 452s 723ms/step - loss: 0.4542 - acc: 0.7881 - val_loss: 0.3723 - val_acc: 0.8367\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 451s 722ms/step - loss: 0.4404 - acc: 0.7959 - val_loss: 0.3730 - val_acc: 0.8415\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 453s 724ms/step - loss: 0.4175 - acc: 0.8093 - val_loss: 0.3250 - val_acc: 0.8643\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 452s 723ms/step - loss: 0.4084 - acc: 0.8148 - val_loss: 0.3691 - val_acc: 0.8370\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 456s 730ms/step - loss: 0.3941 - acc: 0.8250 - val_loss: 0.3333 - val_acc: 0.8570\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 460s 736ms/step - loss: 0.3847 - acc: 0.8292 - val_loss: 0.2977 - val_acc: 0.8813\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 463s 741ms/step - loss: 0.3732 - acc: 0.8361 - val_loss: 0.2984 - val_acc: 0.8783\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 455s 728ms/step - loss: 0.3624 - acc: 0.8393 - val_loss: 0.2976 - val_acc: 0.8662\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 457s 731ms/step - loss: 0.3568 - acc: 0.8428 - val_loss: 0.3120 - val_acc: 0.8645\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 458s 733ms/step - loss: 0.3449 - acc: 0.8501 - val_loss: 0.2680 - val_acc: 0.8910\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - 460s 736ms/step - loss: 0.3373 - acc: 0.8533 - val_loss: 0.2538 - val_acc: 0.8955\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 459s 735ms/step - loss: 0.3224 - acc: 0.8616 - val_loss: 0.2921 - val_acc: 0.8715\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - 463s 740ms/step - loss: 0.3231 - acc: 0.8630 - val_loss: 0.2623 - val_acc: 0.8925\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 465s 743ms/step - loss: 0.3212 - acc: 0.8609 - val_loss: 0.2654 - val_acc: 0.8863\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - 467s 747ms/step - loss: 0.3116 - acc: 0.8632 - val_loss: 0.2465 - val_acc: 0.8978\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 458s 733ms/step - loss: 0.3084 - acc: 0.8657 - val_loss: 0.2910 - val_acc: 0.8708\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - 463s 741ms/step - loss: 0.3015 - acc: 0.8732 - val_loss: 0.2357 - val_acc: 0.8957\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 460s 736ms/step - loss: 0.2948 - acc: 0.8719 - val_loss: 0.2492 - val_acc: 0.8928\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 462s 738ms/step - loss: 0.2979 - acc: 0.8715 - val_loss: 0.2649 - val_acc: 0.8885\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 464s 742ms/step - loss: 0.2952 - acc: 0.8727 - val_loss: 0.2505 - val_acc: 0.8917\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 467s 747ms/step - loss: 0.2855 - acc: 0.8765 - val_loss: 0.2340 - val_acc: 0.9038\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 475s 761ms/step - loss: 0.2838 - acc: 0.8784 - val_loss: 0.2290 - val_acc: 0.9100\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 466s 746ms/step - loss: 0.2817 - acc: 0.8798 - val_loss: 0.2551 - val_acc: 0.8930\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - 465s 744ms/step - loss: 0.2733 - acc: 0.8837 - val_loss: 0.2043 - val_acc: 0.9130\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 466s 746ms/step - loss: 0.2761 - acc: 0.8801 - val_loss: 0.2373 - val_acc: 0.9055\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 469s 750ms/step - loss: 0.2721 - acc: 0.8825 - val_loss: 0.2239 - val_acc: 0.9103\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 469s 750ms/step - loss: 0.2656 - acc: 0.8878 - val_loss: 0.2200 - val_acc: 0.9055\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 468s 749ms/step - loss: 0.2671 - acc: 0.8840 - val_loss: 0.2034 - val_acc: 0.9165\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 475s 760ms/step - loss: 0.2605 - acc: 0.8923 - val_loss: 0.2711 - val_acc: 0.8980\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 470s 751ms/step - loss: 0.2582 - acc: 0.8889 - val_loss: 0.2024 - val_acc: 0.9180\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 472s 754ms/step - loss: 0.2518 - acc: 0.8913 - val_loss: 0.2435 - val_acc: 0.9085\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2621 - acc: 0.8906 - val_loss: 0.2061 - val_acc: 0.9110\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 473s 756ms/step - loss: 0.2443 - acc: 0.8953 - val_loss: 0.2119 - val_acc: 0.9115\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2536 - acc: 0.8931 - val_loss: 0.2009 - val_acc: 0.9133\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2426 - acc: 0.8968 - val_loss: 0.1933 - val_acc: 0.9197\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 474s 758ms/step - loss: 0.2433 - acc: 0.8986 - val_loss: 0.1987 - val_acc: 0.9210\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 474s 758ms/step - loss: 0.2455 - acc: 0.8974 - val_loss: 0.2218 - val_acc: 0.9095\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 477s 763ms/step - loss: 0.2424 - acc: 0.8973 - val_loss: 0.2026 - val_acc: 0.9172\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2401 - acc: 0.9015 - val_loss: 0.2028 - val_acc: 0.9162\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 474s 759ms/step - loss: 0.2437 - acc: 0.8973 - val_loss: 0.2002 - val_acc: 0.9147\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 473s 757ms/step - loss: 0.2359 - acc: 0.9016 - val_loss: 0.1923 - val_acc: 0.9153\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 473s 756ms/step - loss: 0.2390 - acc: 0.9002 - val_loss: 0.2577 - val_acc: 0.8898\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2320 - acc: 0.9054 - val_loss: 0.1882 - val_acc: 0.9233\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 477s 763ms/step - loss: 0.2266 - acc: 0.9062 - val_loss: 0.2067 - val_acc: 0.9185\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 475s 761ms/step - loss: 0.2340 - acc: 0.9052 - val_loss: 0.1883 - val_acc: 0.9237\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 473s 757ms/step - loss: 0.2259 - acc: 0.9040 - val_loss: 0.1927 - val_acc: 0.9233\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 475s 759ms/step - loss: 0.2268 - acc: 0.9035 - val_loss: 0.2495 - val_acc: 0.8990\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 474s 758ms/step - loss: 0.2284 - acc: 0.9028 - val_loss: 0.1800 - val_acc: 0.9310\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 478s 765ms/step - loss: 0.2283 - acc: 0.9033 - val_loss: 0.2053 - val_acc: 0.9222\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2303 - acc: 0.9043 - val_loss: 0.1877 - val_acc: 0.9305\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 474s 758ms/step - loss: 0.2258 - acc: 0.9066 - val_loss: 0.2007 - val_acc: 0.9135\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 475s 759ms/step - loss: 0.2250 - acc: 0.9061 - val_loss: 0.2074 - val_acc: 0.9100\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 474s 759ms/step - loss: 0.2194 - acc: 0.9079 - val_loss: 0.1679 - val_acc: 0.9320\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - 472s 754ms/step - loss: 0.2267 - acc: 0.9062 - val_loss: 0.2530 - val_acc: 0.9030\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - 473s 756ms/step - loss: 0.2182 - acc: 0.9069 - val_loss: 0.2134 - val_acc: 0.9150\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2242 - acc: 0.9078 - val_loss: 0.1862 - val_acc: 0.9262\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2169 - acc: 0.9080 - val_loss: 0.1826 - val_acc: 0.9255\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2146 - acc: 0.9122 - val_loss: 0.1602 - val_acc: 0.9367\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - 475s 760ms/step - loss: 0.2192 - acc: 0.9097 - val_loss: 0.1808 - val_acc: 0.9270\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - 476s 762ms/step - loss: 0.2169 - acc: 0.9074 - val_loss: 0.1772 - val_acc: 0.9283\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - 477s 762ms/step - loss: 0.2097 - acc: 0.9146 - val_loss: 0.1768 - val_acc: 0.9277\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 473s 757ms/step - loss: 0.2164 - acc: 0.9105 - val_loss: 0.1891 - val_acc: 0.9235\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2125 - acc: 0.9131 - val_loss: 0.2395 - val_acc: 0.9045\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 470s 752ms/step - loss: 0.2124 - acc: 0.9108 - val_loss: 0.1826 - val_acc: 0.9275\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 470s 752ms/step - loss: 0.2056 - acc: 0.9161 - val_loss: 0.1777 - val_acc: 0.9298\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2038 - acc: 0.9173 - val_loss: 0.1599 - val_acc: 0.9340\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 471s 753ms/step - loss: 0.2099 - acc: 0.9125 - val_loss: 0.1756 - val_acc: 0.9258\n",
      "Epoch 78/100\n",
      "625/625 [==============================] - 474s 759ms/step - loss: 0.2126 - acc: 0.9114 - val_loss: 0.1752 - val_acc: 0.9265\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2047 - acc: 0.9166 - val_loss: 0.1603 - val_acc: 0.9317\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2052 - acc: 0.9144 - val_loss: 0.1737 - val_acc: 0.9320\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2092 - acc: 0.9158 - val_loss: 0.1677 - val_acc: 0.9317\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.2047 - acc: 0.9160 - val_loss: 0.1897 - val_acc: 0.9255\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - 474s 758ms/step - loss: 0.2080 - acc: 0.9132 - val_loss: 0.2327 - val_acc: 0.9135\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - 472s 756ms/step - loss: 0.2050 - acc: 0.9169 - val_loss: 0.1642 - val_acc: 0.9362\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - 475s 759ms/step - loss: 0.2072 - acc: 0.9162 - val_loss: 0.1575 - val_acc: 0.9392\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - 476s 761ms/step - loss: 0.2027 - acc: 0.9183 - val_loss: 0.1812 - val_acc: 0.9237\n",
      "Epoch 87/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2056 - acc: 0.9140 - val_loss: 0.1927 - val_acc: 0.9227\n",
      "Epoch 88/100\n",
      "625/625 [==============================] - 474s 758ms/step - loss: 0.2027 - acc: 0.9165 - val_loss: 0.1697 - val_acc: 0.9362\n",
      "Epoch 89/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.2033 - acc: 0.9158 - val_loss: 0.1956 - val_acc: 0.9218\n",
      "Epoch 90/100\n",
      "625/625 [==============================] - 472s 754ms/step - loss: 0.2001 - acc: 0.9179 - val_loss: 0.1768 - val_acc: 0.9367\n",
      "Epoch 91/100\n",
      "625/625 [==============================] - 473s 756ms/step - loss: 0.2027 - acc: 0.9178 - val_loss: 0.1677 - val_acc: 0.9315\n",
      "Epoch 92/100\n",
      "625/625 [==============================] - 472s 755ms/step - loss: 0.1968 - acc: 0.9179 - val_loss: 0.1701 - val_acc: 0.9302\n",
      "Epoch 93/100\n",
      "625/625 [==============================] - 473s 757ms/step - loss: 0.1985 - acc: 0.9163 - val_loss: 0.2176 - val_acc: 0.9175\n",
      "Epoch 94/100\n",
      "625/625 [==============================] - 481s 770ms/step - loss: 0.1989 - acc: 0.9205 - val_loss: 0.1790 - val_acc: 0.9273\n",
      "Epoch 95/100\n",
      "625/625 [==============================] - 473s 757ms/step - loss: 0.1951 - acc: 0.9197 - val_loss: 0.1884 - val_acc: 0.9298\n",
      "Epoch 96/100\n",
      "625/625 [==============================] - 473s 757ms/step - loss: 0.1937 - acc: 0.9198 - val_loss: 0.1582 - val_acc: 0.9380\n",
      "Epoch 97/100\n",
      "625/625 [==============================] - 471s 754ms/step - loss: 0.1914 - acc: 0.9221 - val_loss: 0.1596 - val_acc: 0.9377\n",
      "Epoch 98/100\n",
      "625/625 [==============================] - 474s 759ms/step - loss: 0.1895 - acc: 0.9220 - val_loss: 0.1697 - val_acc: 0.9302\n",
      "Epoch 99/100\n",
      "625/625 [==============================] - 478s 764ms/step - loss: 0.2007 - acc: 0.9191 - val_loss: 0.1717 - val_acc: 0.9325\n",
      "Epoch 100/100\n",
      "625/625 [==============================] - 482s 770ms/step - loss: 0.1983 - acc: 0.9187 - val_loss: 0.1958 - val_acc: 0.9330\n",
      "=====================================================================\n",
      "time : 46924.61874675751\n"
     ]
    }
   ],
   "source": [
    "# 최적화\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), # 정규화? 최적화? 훈련과정 설정. 최적화 알고리즘 설정\n",
    "              loss='binary_crossentropy', # 모델 최적화에 사용되는 목적함수\n",
    "              metrics=['acc']) # 훈련을 모니터링 하기위해 사용\n",
    "\n",
    "# 모델 학습하기\n",
    "''' fit() 과 fit_generator() 차이?\n",
    "fit() : 사이킷런의 fit 메소드와 유사. 학습에 사용할 데이터 x와 y 전체를 한번에 입력으로 사용 -> 메모리 많이 사용\n",
    "fit_generator() : 파이썬의 generator를 사용한 것. 대용량을 데이터를 효율적으로 학습하기 위한 것\n",
    "파이썬의 generator를 통해 형성된 데이터들을 batch-by-batch로 학습하는 방법 -> cpu를 parallel(평행? 병렬?)하게 사용할 때 효율적\n",
    "'''\n",
    "\n",
    "start= time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_step, # steps_per_epoch : 한 번의 epoch에서 훈련에 사용할 batch의 개수 지정\n",
    "                    epochs=100, # epoch : 데이터셋을 한 번 훈련하는 과정\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_step # validation_steps : 한 번의 epoch이 끝날 때, 테스트에 사용되는 batch의 개수 지정\n",
    "                    )\n",
    "print('=====================================================================')\n",
    "print('time :', time.time()-start)\n",
    "\n",
    "# model.fit(train_generator,\n",
    "#                     steps_per_epoch=train_step,\n",
    "#                     epochs=30,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=valid_step\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.034616318543753"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "46924.61874675751/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : 0.1558 / test acc : 93.65 %\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터로 평가\n",
    "\n",
    "model.save('CNN_epoch_100_batch_32.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator,\n",
    "                                               steps=test_step,\n",
    "                                               workers=4)\n",
    "\n",
    "print(f'test loss : {test_loss:.4f} / test acc : {test_acc*100:.2f} %')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
